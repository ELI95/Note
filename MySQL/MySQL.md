- 一主多从的主备切换流程
  - GTID=server_uuid:gno
    - 实例 B 指定主库 A’，基于主备协议建立连接
    - 实例 B 把 set_b 发给主库 A’
    - 实例 A’算出 set_a 与 set_b 的差集，也就是所有存在于 set_a，但是不存在于 set_b 的 GTID 的集合，判断 A’本地是否包含了这个差集需要的所有 binlog 事务。 a. 如果不包含，表示 A’已经把实例 B 需要的 binlog 给删掉了，直接返回错误； b. 如果确认全部包含，A’从自己的 binlog 文件里面，找出第一个不在 set_b 的事务，发给 B
    - 之后就从这个事务开始，往后读文件，按顺序取 binlog 发给 B 去执行

- 读写分离
  - 处理过期读
    - GTID 方案
      - trx1 事务更新完成后，从返回包直接获取这个事务的 GTID，记为 gtid1
        - 需要将参数 session_track_gtids 设置为 OWN_GTID，然后通过 API 接口 mysql_session_track_get_first 从返回包解析出 GTID 的值即可
      - 选定一个从库执行查询语句
      - 在从库上执行 select wait_for_executed_gtid_set(gtid1, 1)
      - 如果返回值是 0，则在这个从库执行查询语句
      - 否则，到主库执行查询语句

- 检测 MySQL 实例健康状态
  - 外部检测
    - select 1
      - 当同时在执行的语句超过了设置的 innodb_thread_concurrency 的值时，不能检测到异常
      - 设置 innodb_thread_concurrency 参数，用来控制 InnoDB 的并发线程上限
      - 通常情况下，建议把 innodb_thread_concurrency 设置为 64~128 之间的值
      - 并发连接和并发查询，并发连接数达到几千个影响并不大，就是多占一些内存而已。我们应该关注的是并发查询，因为并发查询太高才是 CPU 杀手
      - 在线程进入锁等待以后，并发线程的计数会减一，也就是说等行锁（也包括间隙锁）的线程是不算在 innodb_thread_concurrency 里面的
    - 查表判断
      - 更新事务要写 binlog，而一旦 binlog 所在磁盘的空间占用率达到 100%，那么所有的更新语句和事务提交的 commit 语句就都会被堵住。但是，系统这时候还是可以正常读数据的
    - update 系统表
      - 为了让主备之间的更新不产生冲突，我们可以在 mysql.health_check 表上存入多行数据，并用 A、B 的 server_id 做主键
      - 判定慢
  - 内部统计
    - performance_schema

- lock in share mode 只锁覆盖索引，但是如果是 for update 就不一样了。 执行 for update 时，系统会认为你接下来要更新数据，因此会顺便给主键索引上满足条件的行加上行锁
- delete 语句加锁的逻辑，与 select ... for update 是类似的
- 在删除数据的时候尽量加 limit。这样不仅可以控制删除数据的条数，让操作更安全，还可以减小加锁的范围
- next-key lock 实际上是间隙锁和行锁加起来的结果，我们在分析加锁规则的时候可以用 next-key lock 来分析。但是要知道，具体执行的时候，是要分成间隙锁和行锁两段来执行的

- 分析加锁范围时，一定要配合语句执行逻辑来进行
- 在执行过程中，通过树搜索的方式定位记录的时候，用的是“等值查询”的方法
- 锁是在执行过程中一个一个加的，而不是一次性加上去的
- 由于锁是一个个加的，要避免死锁，对同一组资源，要按照尽量相同的顺序访问
- 在发生死锁的时刻，for update 这条语句占有的资源更多，回滚成本更大，所以 InnoDB 选择了回滚成本更小的 lock in share mode 语句，来回滚
- 间隙是由这个间隙右边的那个记录定义的

- 预防误删数据
  - 账号分离
    - 只给业务开发同学 DML 权限，而不给 truncate/drop 权限。而如果业务开发人员有 DDL 需求的话，也可以通过开发管理系统得到支持
    - 即使是 DBA 团队成员，日常也都规定只使用只读账号，必要的时候才使用有更新权限的账号
  - 制定操作规范
    - 在删除数据表之前，必须先对表做改名操作。然后，观察一段时间，确保对业务无影响以后再删除这张表
    - 改表名的时候，要求给表名加固定的后缀（比如加 _to_be_deleted)，然后删除表的动作必须通过管理系统执行。并且，管理系统删除表的时候，只能删除固定后缀的表
- 误删数据恢复
  - 误删库或者表后，恢复数据的思路主要就是通过备份，再加上应用 binlog 的方式
  - 要求备份系统定期备份全量日志，而且需要确保 binlog 在被从本地删除之前已经做了备份
  - 延迟复制备库

- MySQL 中的 kill 命令
  - kill query + 线程 id，表示终止这个线程中正在执行的语句
  - kill connection + 线程 id，这里 connection 可缺省，表示断开这个线程的连接，当然如果这个线程有语句正在执行，也是要先停止正在执行的语句的
- 为什么 kill 不掉
  - 发送 kill 命令的客户端，并没有强行停止目标线程的执行，而只是设置了个状态，并唤醒对应的线程。而被 kill 的线程，需要执行到判断状态的“埋点”，才会开始进入终止逻辑阶段。并且，终止逻辑本身也是需要耗费时间的
- 具体场景
  - 线程没有执行到判断线程状态的逻辑
    - 由于 IO 压力过大，读写 IO 的函数一直无法返回，导致不能及时判断线程的状态
  - 终止逻辑耗时较长
    - 超大事务执行期间被 kill。这时候，回滚操作需要对事务执行期间生成的所有新数据版本做回收操作，耗时很长
    - 大查询回滚。如果查询过程中生成了比较大的临时文件，加上此时文件系统压力大，删除临时文件可能需要等待 IO 资源，导致耗时较长
    - DDL 命令执行到最后阶段，如果被 kill，需要删除中间过程的临时文件，也可能受 IO 资源影响耗时较久
- 如果直接在客户端通过 Ctrl+C 命令，是不是就可以直接终止线程呢？
  - 不可以
  - 由于 MySQL 是停等协议，所以这个线程执行的语句还没有返回的时候，再往这个连接里面继续发命令也是没有用的
  - 实际上，执行 Ctrl+C 的时候，是 MySQL 客户端另外启动一个连接，然后发送一个 kill query 命令
  
- MySQL 连接参数
  - -A
    - 关闭客户端自动补全
    - 当使用默认参数连接的时候，MySQL 客户端会提供一个本地库名和表名补全的功能。为了实现这个功能，客户端在连接成功后，需要多做一些操作
        - 执行 show databases
        - 切到目标库，执行 show tables
        - 把这两个命令的结果用于构建一个本地的哈希表
    - 在这些操作中，最花时间的就是第三步在本地构建哈希表的操作。所以，当一个库中的表个数非常多的时候，这一步就会花比较长的时间
  - –q
    – 让客户端变得更快
      - 关闭客户端自动补全功能
      - mysql_store_result 需要申请本地内存来缓存查询结果，如果查询结果太大，会耗费较多的本地内存，可能会影响客户端本地机器的性能
      - 不会把执行命令记录到本地的命令历史文件
    - MySQL 客户端发送请求后，接收服务端返回结果的方式有两种
      - 一种是本地缓存，也就是在本地开一片内存，先把结果存起来。如果你用 API 开发，对应的就是 mysql_store_result 方法
      - 另一种是不缓存，读一个处理一个。如果你用 API 开发，对应的就是 mysql_use_result 方法
    - MySQL 客户端默认采用第一种方式，而如果加上 –q 参数，就会使用第二种不缓存的方式。
    - 采用不缓存的方式时，如果本地处理得慢，就会导致服务端发送结果被阻塞，因此会让服务端变慢

- MySQL大查询
  - MySQL 是边读边发的，查询的结果是分段发给客户端的，对于数据量很大的查询结果来说，不会在 server 端保存完整的结果集。所以，如果客户端读结果不及时，会堵住 MySQL 的查询过程，但是不会把内存打爆
  - 对于 InnoDB 引擎内部，由于有淘汰策略，大查询也不会导致内存暴涨。并且，由于 InnoDB 对 LRU 算法做了改进，冷数据的全表扫描，对 Buffer Pool 的影响也能做到可控

- 如果客户端由于压力过大，迟迟不能接收数据，会对服务端造成什么严重的影响
  - 造成了长事务
    - 如果前面的语句有更新，意味着它们在占用着行锁，会导致别的语句更新被锁住
    - 当然读的事务也有问题，就是会导致 undo log 不能被回收，导致回滚段空间膨胀

- join
  - Index Nested-Loop Join
    - 可以用上被驱动表上的索引
    - 让小表做驱动表性能更好
  - Block Nested-Loop Join
    - 不能使用被驱动表上的索引
    - 让小表做驱动表性能更好
    - join_buffer
      - 维护的是一个无序数组
    - join_buffer_size 越大，一次可以放入的行越多，分成的段数也就越少，对被驱动表的全表扫描次数就越少
    - 在大表上的 join 操作，可能要扫描被驱动表很多次，会占用大量的系统资源。所以这种 join 尽量不要用
  - 使用场景
    - 如果可以使用被驱动表的索引，join 语句还是有其优势的
    - 不能使用被驱动表的索引，只能使用 Block Nested-Loop Join 算法，这样的语句就尽量不要使用
    - 在使用 join 的时候，应该让小表做驱动表
  - 在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，过滤完成之后，计算参与 join 的各个字段的总数据量，数据量小的那个表，就是“小表”，应该作为驱动表

- join优化
  - Multi-Range Read
    - MRR 能够提升性能的核心在于，这条查询语句在索引 a 上做的是一个范围查询（也就是说，这是一个多值查询），可以得到足够多的主键 id。这样通过排序以后，再去主键索引查数据，才能体现出“顺序性”的优势
    - 因为大多数的数据都是按照主键递增顺序插入得到的，所以我们可以认为，如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能
    - read_rnd_buffer
  - Index Nested-Loop Join
    - Batched Key Access
      - 复用 join_buffer
      - MRR
  - Block Nested-Loop Join
    - BNL 算法对系统的影响
      - 可能会多次扫描被驱动表，占用磁盘 IO 资源
      - 判断 join 条件需要执行 M*N 次对比（M、N 分别是两张表的行数），如果是大表就会占用非常多的 CPU 资源
      - 可能会导致 Buffer Pool 的热数据被淘汰，影响内存命中率
    - 优化
      - 让 join 语句能够用上被驱动表上的索引，来触发 BKA 算法，提升查询性能
        - 给被驱动表的 join 字段加上索引
        - 基于临时表的改进方案，对于能够提前过滤出小数据的 join 语句来说，效果还是很好的
  - Hash join
    - MySQL5.7 版本的 join_buffer 里面维护的是一个无序数组，而不是哈希表
  - 使用 left join 时，左边的表不一定是驱动表
  - 三表join
    - MySQL 的 join 算法基于嵌套循环算法, 三表 join 的时候，联表顺序并不是两两联合之后，再去联合第三张表，而是驱动表的一条记录穿到底，匹配完所有关联表之后，再取驱动表的下一条记录重复联表操作
    - 尽量使用 BKA 算法，让每一次参与 join 的驱动表的数据集，越小越好，因为这样我们的驱动表就会越小

- 用户临时表
  - 特性
    - 可以使用各种引擎类型。如果是使用 InnoDB 引擎或者 MyISAM 引擎的临时表，写数据的时候是写到磁盘上的。当然，临时表也可以使用 Memory 引擎
    - 建表语法是 create temporary table …
    - 临时表只能被创建它的 session 访问，在这个 session 结束的时候，会自动删除临时表
    - 临时表可以与普通表同名
    - 不同 session 的临时表是可以重名的
    - session A 内有同名的临时表和普通表的时候，show create 语句，以及增删改查语句访问的是临时表
    - show tables 命令不显示临时表
  - 存储
    - 当创建InnoDB临时表时，MySQL 要给这个 InnoDB 表创建一个 frm 文件保存表结构定义，还要有地方保存表数据
      - frm 文件放在临时文件目录下，文件名的后缀是.frm，前缀是“#sql{进程 id}{线程 id}{序列号}”
      - 在 5.6 版本以及之前，MySQL 会在临时文件目录下创建一个相同前缀的以.ibd 为后缀的文件，用来存放数据文件
      - 从 5.7 版本开始，MySQL 引入了一个临时文件表空间，专门用来存放临时文件的数据
    - MySQL 维护数据表，除了物理上要有文件外，内存里面也有一套机制区别不同的表，每个表都对应一个 table_def_key
      - 普通表的 table_def_key 的值是由“库名 + 表名”得到的，所以如果你要在同一个库下创建两个同名的普通表，创建第二个表的过程中就会发现 table_def_key 已经存在了
      - 临时表的 table_def_key 在“库名 + 表名”基础上，又加入了“server_id+thread_id”
    - 每个线程都维护了自己的临时表链表。这样每次 session 内操作表的时候，先遍历链表，检查是否有这个名字的临时表，如果有就优先操作临时表，如果没有再操作普通表；在 session 结束的时候，对链表里的每个临时表，执行 “DROP TEMPORARY TABLE + 表名”操作
  - 应用
    - 由于不用担心线程之间的重名冲突，临时表经常会被用在复杂查询的优化过程中。例如：分库分表系统的跨库查询
  - 主备复制
    - 如果当前的 binlog_format=row，那么跟临时表有关的语句，就不会记录到 binlog 里。也就是说，只在 binlog_format=statement/mixed 的时候，binlog 中才会记录临时表的操作
    - drop table 命令记录 binlog 的时候，就必须对语句做改写。“/* generated by server */”说明了这是一个被服务端改写过的命令
    - MySQL 在记录 binlog 的时候，会把主库执行这个语句的线程 id 写到 binlog 中。这样，在备库的应用线程就能够知道执行每个语句的主库线程 id，并利用这个线程 id 来构造临时表的 table_def_key
- 内部临时表
  - 使用场景示例
    - union
    - group by
      - 优化方案
        - 尽量让 group by 过程用上表的索引，确认方法是 explain 结果里没有 Using temporary
        - 如果 group by 需要统计的数据量不大，尽量只使用内存临时表；也可以通过适当调大 tmp_table_size 参数，来避免用到磁盘临时表
        - 如果数据量实在太大，使用 SQL_BIG_RESULT 这个提示，来告诉优化器直接使用排序算法得到 group by 的结果
  - MySQL 什么时候会使用内部临时表
    - 如果语句执行过程可以一边读数据，一边直接得到结果，是不需要额外内存的，否则就需要额外的内存，来保存中间结果
    - join_buffer 是无序数组，sort_buffer 是有序数组，临时表是二维表结构
    - 如果执行逻辑需要用到二维表特性，就会优先考虑使用临时表

- 内存表
  - 指的是使用 Memory 引擎的表，建表语法是 create table … engine=memory。这种表的数据都保存在内存里，系统重启的时候会被清空，但是表结构还在
  - 内存表的数据部分以数组的方式单独存放，而主键 id 索引里，存的是每个数据的位置。主键 id 是 hash 索引
  - 哈希索引不支持范围查询，但是内存表也是支持 B-Tree 索引的，可以在需要支持范围查询的列上创建一个 B-Tree 索引
  - 锁粒度问题
    - 内存表不支持行锁，只支持表锁。因此，一张表只要有更新，就会堵住其他所有在这个表上的读写操作
    - 跟行锁比起来，表锁对并发访问的支持不够好。所以，内存表的锁粒度问题，决定了它在处理并发事务的时候，性能也不会太好
  - 数据持久性问题
    - 数据库重启的时候，所有的内存表的数据都会被清空
    - 由于重启会丢数据，如果一个备库重启，会导致主备同步线程停止；如果主库跟这个备库是双 M 架构，还可能导致主库的内存表数据被删掉
  - 内存表并不适合在生产环境上作为普通数据表使用
  - 适用场景
    - 用户内存临时表
      - 用户内存临时表不会被其他线程访问，没有并发性的问题
      - 用户内存临时表重启后也是需要删除的，清空数据这个问题不存在
      - 备库的用户内存临时表也不会影响主库的用户线程
    - 内存表支持 hash 索引，利用这个特性可以加速一些复杂查询

- 自增主键
  - 自增值的存储
    - MyISAM 引擎的自增值保存在数据文件中。
    - InnoDB 引擎
      - MySQL 5.7 及之前的版本，自增值保存在内存里，并没有持久化
      - MySQL 8.0 版本后，才有了“自增值持久化”的能力
        - 将自增值的变更记录在了 redo log 中，重启的时候依靠 redo log 恢复重启之前的值
  - sql 语句执行失败也不会回退自增 id，只保证了自增 id 是递增的，但不保证是连续的
  - 自增锁的优化
    - innodb_autoinc_lock_mode（默认值是 1）
      - 0：采用之前 MySQL 5.0 版本的策略，即语句执行结束后才释放锁
      - 1：普通 insert 语句，自增锁在申请之后就马上释放；类似 insert … select 这样的批量插入数据的语句，自增锁还是要等语句结束后才被释放
      - 2：所有的申请自增主键的动作都是申请后就释放锁
    - 为什么默认设置下，insert … select 要使用语句级的锁？为什么这个参数的默认值不是 2？
      - 数据的一致性
        - 一种思路是，让原库的批量插入数据语句，固定生成连续的 id 值。所以，自增锁直到语句执行结束才释放，就是为了达到这个目的
        - 另一种思路是，在 binlog 里面把插入数据的操作都如实记录进来，到备库执行的时候，不再依赖于自增主键去生成。这种情况，其实就是 innodb_autoinc_lock_mode 设置为 2，同时 binlog_format 设置为 row
    - 在生产上，尤其是有 insert … select 这种批量插入数据的场景时，从并发插入数据性能的角度考虑，我建议你这样设置：innodb_autoinc_lock_mode=2 ，并且 binlog_format=row. 这样做，既能提升并发性，又不会出现数据一致性问题
      - 批量插入数据，包含的语句类型是 insert … select、replace … select 和 load data 语句
    - 在普通的 insert 语句里面包含多个 value 值的情况下，即使 innodb_autoinc_lock_mode 设置为 1，也不会等语句执行完成才释放锁
      - 普通的 insert 语句在申请自增 id 的时候，是可以精确计算出需要多少个 id 的，然后一次性申请，申请完成后锁就可以释放了
    - 批量插入数据的语句，之所以需要这么设置，是因为“不知道要预先申请多少个 id”
      - 对于批量插入数据的语句，MySQL 有一个批量申请自增 id 的策略：同一个语句去申请自增 id，语句执行过程中，第一次申请自增 id，会分配 1 个，以后每次申请到的自增 id 个数都是上一次的两倍

- insert
  - insert … select
    - 在可重复读隔离级别下，binlog_format=statement 时，这个语句会给 select 的表里扫描到的记录和间隙加读锁
      - 日志和数据的一致性
      - 如果没有锁的话，就可能出现 session B 的 insert 语句先执行，但是后写入 binlog 的情况
    - 如果 insert 和 select 的对象是同一个表，则有可能会造成循环写入。这种情况下可以引入用户临时表来做优化
  - insert 语句如果出现唯一键冲突，会在冲突的唯一值上加共享锁
    - 如果冲突的是主键索引，就加记录锁，唯一索引加 next-key lock
    - 碰到由于唯一键约束导致报错后，要尽快提交或回滚事务，避免加锁时间过长
  - insert into … on duplicate key update
    - 插入一行数据，如果碰到唯一键约束，就执行后面的更新语句
    - 如果有多个列违反了唯一性约束，就会按照索引的顺序，修改跟第一个索引冲突的行

- 分区表
  - 从 server 层看的话，一个分区表就只是一个表，因此所有分区共用同一个 MDL 锁
  - 在引擎层，认为这是不同的表，因此 MDL 锁之后的执行过程，会根据分区表规则，只访问必要的分区

- 分库分表
  - 场景
    - 分表的原动力在于 MySQL 单表性能问题
    - 分库的原动力主要是单实例的写入容量限制和写入放大问题
  - Sharding + Proxy
    - DB proxy
      - 链路过长，每层都会增加响应时间
      - 网络单点，并且往往是整个公司层面的单点
      - 部分产品对Prepare 应用不友好，需要绑定 connection 信息
    - JDBC proxy
      - 语言限制
      - 接入繁琐
      - DB 不透明
    - Sharding + Proxy 本质上只解决了一个问题，那就是单机数据容量问题
    - 分库分表为了解决一个问题，引入了很多成本，从长久看这种方案会逐步被新的解决方案替代
  - 解决思路
    - 最大程度地提升整个写入容量
      - 以 AWS Aurora 为代表 RDS ，它以  Log is database 为理念，将复杂的随机写入简化为顺序写的 Log，并通过将计算与存储分离，把复杂的数据持久化、一致性、数据合并都扔给一个高可用的共享存储系统来完成，进而打开写入的天花板，将昂贵的写入容量提升一个量级
    - 承认分片的必要性，将这种分片的策略集成到一套整体的分布式数据库体系中，同时通过 Paxos/Raft  复制协议加上多实例节点来实现数据强一致的高可用
      - 其中代表产品有 Google 的 Spanner & F1、TiDB（https://github.com/pingcap/tidb）、CockRoachDB（https://github.com/cockroachdb/cockroach） 等，是比较理想的 Sharding + Proxy 的替代方案

- 自增 id 上限
  - 表的自增 id 达到上限后，再申请时它的值就不会改变，进而导致继续插入数据时报主键冲突的错误
  - row_id 达到上限后，则会归 0 再重新递增，如果出现相同的 row_id，后写的数据会覆盖之前的数据
  - Xid 只需要不在同一个 binlog 文件中出现重复值即可。虽然理论上会出现重复值，但是概率极小，可以忽略不计。
  - InnoDB 的 max_trx_id 递增值每次 MySQL 重启都会被保存起来，所以我们文章中提到的脏读的例子就是一个必现的 bug，好在留给我们的时间还很充裕
  - thread_id，系统保存了一个全局变量 thread_id_counter，每新建一个连接，就将 thread_id_counter 赋值给这个新连接的线程变量，唯一数组

- 学习方法
  - 做笔记
  - 实践
